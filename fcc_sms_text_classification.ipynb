{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  # !pip install tf-nightly\n",
        "  pass\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "# !pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files (cross-platform local download)\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "train_url = 'https://cdn.freecodecamp.org/project-data/sms/train-data.tsv'\n",
        "train_file_path = 'train-data.tsv'\n",
        "\n",
        "if not os.path.exists(train_file_path):\n",
        "    print('Downloading train dataset ...')\n",
        "    urlretrieve(train_url, train_file_path)\n",
        "\n",
        "test_url = 'https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv'\n",
        "test_file_path = 'valid-data.tsv'\n",
        "\n",
        "if not os.path.exists(test_file_path):\n",
        "    print('Downloading test dataset ...')\n",
        "    urlretrieve(test_url, test_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess data\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv(train_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "test_df = pd.read_csv(test_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# Map labels to binary\n",
        "train_df['label'] = train_df['label'].map({'ham': 0, 'spam': 1})\n",
        "test_df['label'] = test_df['label'].map({'ham': 0, 'spam': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "131/131 - 7s - loss: 0.2097 - accuracy: 0.9277 - val_loss: 0.0504 - val_accuracy: 0.9885 - 7s/epoch - 55ms/step\n",
            "Epoch 2/20\n",
            "131/131 - 7s - loss: 0.2097 - accuracy: 0.9277 - val_loss: 0.0504 - val_accuracy: 0.9885 - 7s/epoch - 55ms/step\n",
            "Epoch 2/20\n",
            "131/131 - 5s - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.0489 - val_accuracy: 0.9871 - 5s/epoch - 38ms/step\n",
            "Epoch 3/20\n",
            "131/131 - 5s - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.0489 - val_accuracy: 0.9871 - 5s/epoch - 38ms/step\n",
            "Epoch 3/20\n",
            "131/131 - 5s - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0596 - val_accuracy: 0.9864 - 5s/epoch - 37ms/step\n",
            "Epoch 4/20\n",
            "131/131 - 5s - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0596 - val_accuracy: 0.9864 - 5s/epoch - 37ms/step\n",
            "Epoch 4/20\n",
            "131/131 - 5s - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0554 - val_accuracy: 0.9849 - 5s/epoch - 37ms/step\n",
            "Epoch 5/20\n",
            "131/131 - 5s - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0554 - val_accuracy: 0.9849 - 5s/epoch - 37ms/step\n",
            "Epoch 5/20\n",
            "131/131 - 5s - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0590 - val_accuracy: 0.9871 - 5s/epoch - 37ms/step\n",
            "Epoch 6/20\n",
            "131/131 - 5s - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0590 - val_accuracy: 0.9871 - 5s/epoch - 37ms/step\n",
            "Epoch 6/20\n",
            "131/131 - 5s - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0570 - val_accuracy: 0.9878 - 5s/epoch - 37ms/step\n",
            "Epoch 7/20\n",
            "131/131 - 5s - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0570 - val_accuracy: 0.9878 - 5s/epoch - 37ms/step\n",
            "Epoch 7/20\n",
            "131/131 - 5s - loss: 4.3771e-04 - accuracy: 0.9998 - val_loss: 0.0570 - val_accuracy: 0.9878 - 5s/epoch - 39ms/step\n",
            "Epoch 8/20\n",
            "131/131 - 5s - loss: 4.3771e-04 - accuracy: 0.9998 - val_loss: 0.0570 - val_accuracy: 0.9878 - 5s/epoch - 39ms/step\n",
            "Epoch 8/20\n",
            "131/131 - 5s - loss: 2.0996e-04 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9871 - 5s/epoch - 37ms/step\n",
            "Epoch 9/20\n",
            "131/131 - 5s - loss: 2.0996e-04 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9871 - 5s/epoch - 37ms/step\n",
            "Epoch 9/20\n",
            "131/131 - 5s - loss: 9.6758e-05 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9871 - 5s/epoch - 37ms/step\n",
            "Epoch 10/20\n",
            "131/131 - 5s - loss: 9.6758e-05 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9871 - 5s/epoch - 37ms/step\n",
            "Epoch 10/20\n",
            "131/131 - 5s - loss: 5.8264e-05 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9878 - 5s/epoch - 37ms/step\n",
            "Epoch 11/20\n",
            "131/131 - 5s - loss: 5.8264e-05 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9878 - 5s/epoch - 37ms/step\n",
            "Epoch 11/20\n",
            "131/131 - 5s - loss: 4.1333e-05 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9871 - 5s/epoch - 36ms/step\n",
            "Epoch 12/20\n",
            "131/131 - 5s - loss: 4.1333e-05 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9871 - 5s/epoch - 36ms/step\n",
            "Epoch 12/20\n",
            "131/131 - 5s - loss: 2.7727e-05 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9871 - 5s/epoch - 36ms/step\n",
            "Epoch 13/20\n",
            "131/131 - 5s - loss: 2.7727e-05 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9871 - 5s/epoch - 36ms/step\n",
            "Epoch 13/20\n",
            "131/131 - 5s - loss: 2.1103e-05 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9871 - 5s/epoch - 36ms/step\n",
            "Epoch 14/20\n",
            "131/131 - 5s - loss: 2.1103e-05 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9871 - 5s/epoch - 36ms/step\n",
            "Epoch 14/20\n",
            "131/131 - 5s - loss: 1.5678e-05 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9871 - 5s/epoch - 38ms/step\n",
            "Epoch 15/20\n",
            "131/131 - 5s - loss: 1.5678e-05 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9871 - 5s/epoch - 38ms/step\n",
            "Epoch 15/20\n",
            "131/131 - 6s - loss: 1.3445e-05 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9871 - 6s/epoch - 43ms/step\n",
            "Epoch 16/20\n",
            "131/131 - 6s - loss: 1.3445e-05 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9871 - 6s/epoch - 43ms/step\n",
            "Epoch 16/20\n",
            "131/131 - 6s - loss: 1.0412e-05 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9871 - 6s/epoch - 43ms/step\n",
            "Epoch 17/20\n",
            "131/131 - 6s - loss: 1.0412e-05 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9871 - 6s/epoch - 43ms/step\n",
            "Epoch 17/20\n",
            "131/131 - 6s - loss: 8.9174e-06 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9871 - 6s/epoch - 42ms/step\n",
            "Epoch 18/20\n",
            "131/131 - 6s - loss: 8.9174e-06 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9871 - 6s/epoch - 42ms/step\n",
            "Epoch 18/20\n",
            "131/131 - 5s - loss: 7.3756e-06 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9871 - 5s/epoch - 40ms/step\n",
            "Epoch 19/20\n",
            "131/131 - 5s - loss: 7.3756e-06 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9871 - 5s/epoch - 40ms/step\n",
            "Epoch 19/20\n",
            "131/131 - 5s - loss: 6.2967e-06 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9871 - 5s/epoch - 40ms/step\n",
            "Epoch 20/20\n",
            "131/131 - 5s - loss: 6.2967e-06 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9871 - 5s/epoch - 40ms/step\n",
            "Epoch 20/20\n",
            "131/131 - 5s - loss: 5.3521e-06 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9878 - 5s/epoch - 41ms/step\n",
            "131/131 - 5s - loss: 5.3521e-06 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9878 - 5s/epoch - 41ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2228a16abf0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize and pad sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(train_df['message'])\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_df['message'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df['message'])\n",
        "\n",
        "max_length = 200\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# Build and train model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(20000, 64, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_padded, train_df['label'], epochs=20, validation_data=(test_padded, test_df['label']), verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.7970249e-06, 'ham']\n",
            "[3.7970249e-06, 'ham']\n"
          ]
        }
      ],
      "source": [
        "# function to predict messages based on model\n",
        "def predict_message(pred_text):\n",
        "    sequence = tokenizer.texts_to_sequences([pred_text])\n",
        "    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
        "    prediction = model.predict(padded, verbose=0)[0][0]\n",
        "    label = 'spam' if prediction > 0.5 else 'ham'\n",
        "    print([prediction, label]) # debuging\n",
        "    return [prediction, label]\n",
        "  \n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.7970249e-06, 'ham']\n",
            "[0.99963135, 'spam']\n",
            "[3.6171704e-07, 'ham']\n",
            "[0.9999906, 'spam']\n",
            "[0.99999976, 'spam']\n",
            "[2.0628346e-07, 'ham']\n",
            "[1.94368e-06, 'ham']\n",
            "You passed the challenge. Great job!\n",
            "[2.0628346e-07, 'ham']\n",
            "[1.94368e-06, 'ham']\n",
            "You passed the challenge. Great job!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
